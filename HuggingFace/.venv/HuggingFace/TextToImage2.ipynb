{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-23T17:26:35.860314Z",
     "start_time": "2025-12-23T17:26:31.824564Z"
    }
   },
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "#Load the Stable Diffusion Model\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id , torch_dtype=torch.float16)\n",
    "\n",
    "#Move the model to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "#Define your text prompt\n",
    "prompt = \"Flying cars soar over a futuristic cityscape at sunset.\"\n",
    "\n",
    "#Generate the image\n",
    "with torch.autocast(\"cuda\"): #Using autocast for mixed precision (faster on GPU)\n",
    "    image = pipe(prompt).images[0]\n",
    "# The pipeline shows a progress bar by default in the terminal\n",
    "\n",
    "\n",
    "#Save the image\n",
    "image.save(\"Generate_image.png\")\n",
    "print(\"Image saved as generated_image.png\")"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace prims; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at C:\\Users\\KIIT0001\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\torch\\_prims\\__init__.py:37; latest registration was registered at C:\\Users\\KIIT0001\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\torch\\_prims\\__init__.py:37",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdiffusers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m StableDiffusionPipeline\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m#Load the Stable Diffusion Model\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\diffusers\\__init__.py:5\u001B[39m\n\u001B[32m      1\u001B[39m __version__ = \u001B[33m\"\u001B[39m\u001B[33m0.36.0\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      6\u001B[39m     DIFFUSERS_SLOW_IMPORT,\n\u001B[32m      7\u001B[39m     OptionalDependencyNotAvailable,\n\u001B[32m      8\u001B[39m     _LazyModule,\n\u001B[32m      9\u001B[39m     is_accelerate_available,\n\u001B[32m     10\u001B[39m     is_bitsandbytes_available,\n\u001B[32m     11\u001B[39m     is_flax_available,\n\u001B[32m     12\u001B[39m     is_gguf_available,\n\u001B[32m     13\u001B[39m     is_k_diffusion_available,\n\u001B[32m     14\u001B[39m     is_librosa_available,\n\u001B[32m     15\u001B[39m     is_note_seq_available,\n\u001B[32m     16\u001B[39m     is_nvidia_modelopt_available,\n\u001B[32m     17\u001B[39m     is_onnx_available,\n\u001B[32m     18\u001B[39m     is_opencv_available,\n\u001B[32m     19\u001B[39m     is_optimum_quanto_available,\n\u001B[32m     20\u001B[39m     is_scipy_available,\n\u001B[32m     21\u001B[39m     is_sentencepiece_available,\n\u001B[32m     22\u001B[39m     is_torch_available,\n\u001B[32m     23\u001B[39m     is_torchao_available,\n\u001B[32m     24\u001B[39m     is_torchsde_available,\n\u001B[32m     25\u001B[39m     is_transformers_available,\n\u001B[32m     26\u001B[39m )\n\u001B[32m     29\u001B[39m \u001B[38;5;66;03m# Lazy Import based on\u001B[39;00m\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# https://github.com/huggingface/transformers/blob/main/src/transformers/__init__.py\u001B[39;00m\n\u001B[32m     31\u001B[39m \n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# When adding a new object to this init, please add it to `_import_structure`. The `_import_structure` is a dictionary submodule to list of object names,\u001B[39;00m\n\u001B[32m     33\u001B[39m \u001B[38;5;66;03m# and is used to defer the actual importing for when the objects are requested.\u001B[39;00m\n\u001B[32m     34\u001B[39m \u001B[38;5;66;03m# This way `import diffusers` provides the names in the namespace without actually importing anything (and especially none of the backends).\u001B[39;00m\n\u001B[32m     36\u001B[39m _import_structure = {\n\u001B[32m     37\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mconfiguration_utils\u001B[39m\u001B[33m\"\u001B[39m: [\u001B[33m\"\u001B[39m\u001B[33mConfigMixin\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     38\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mguiders\u001B[39m\u001B[33m\"\u001B[39m: [],\n\u001B[32m   (...)\u001B[39m\u001B[32m     64\u001B[39m     ],\n\u001B[32m     65\u001B[39m }\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\diffusers\\utils\\__init__.py:131\u001B[39m\n\u001B[32m    129\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlogging\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_logger\n\u001B[32m    130\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01moutputs\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseOutput\n\u001B[32m--> \u001B[39m\u001B[32m131\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpeft_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m    132\u001B[39m     check_peft_version,\n\u001B[32m    133\u001B[39m     delete_adapter_layers,\n\u001B[32m    134\u001B[39m     get_adapter_name,\n\u001B[32m    135\u001B[39m     get_peft_kwargs,\n\u001B[32m    136\u001B[39m     recurse_remove_peft_layers,\n\u001B[32m    137\u001B[39m     scale_lora_layers,\n\u001B[32m    138\u001B[39m     set_adapter_layers,\n\u001B[32m    139\u001B[39m     set_weights_and_activate_adapters,\n\u001B[32m    140\u001B[39m     unscale_lora_layers,\n\u001B[32m    141\u001B[39m )\n\u001B[32m    142\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpil_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PIL_INTERPOLATION, make_image_grid, numpy_to_pil, pt_to_pil\n\u001B[32m    143\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mremote_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m remote_decode\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\diffusers\\utils\\peft_utils.py:26\u001B[39m\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m logging\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimport_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m is_peft_available, is_peft_version, is_torch_available\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtorch_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m empty_device_cache\n\u001B[32m     29\u001B[39m logger = logging.get_logger(\u001B[34m__name__\u001B[39m)\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_torch_available():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\diffusers\\utils\\torch_utils.py:27\u001B[39m\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimport_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m is_torch_available, is_torch_mlu_available, is_torch_npu_available, is_torch_version\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_torch_available():\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m     28\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfft\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m fftn, fftshift, ifftn, ifftshift\n\u001B[32m     30\u001B[39m     BACKEND_SUPPORTS_TRAINING = {\u001B[33m\"\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mxpu\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mmps\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mdefault\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\torch\\__init__.py:2680\u001B[39m\n\u001B[32m   2676\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfunc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m vmap \u001B[38;5;28;01mas\u001B[39;00m vmap\n\u001B[32m   2679\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m TYPE_CHECKING:\n\u001B[32m-> \u001B[39m\u001B[32m2680\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _meta_registrations\n\u001B[32m   2682\u001B[39m \u001B[38;5;66;03m# Enable CUDA Sanitizer\u001B[39;00m\n\u001B[32m   2683\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mTORCH_CUDA_SANITIZER\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m os.environ:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\torch\\_meta_registrations.py:12\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_prims_common\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mutils\u001B[39;00m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SymBool, SymFloat, Tensor\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_decomp\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     13\u001B[39m     _add_op_to_registry,\n\u001B[32m     14\u001B[39m     _convert_out_params,\n\u001B[32m     15\u001B[39m     global_decomposition_table,\n\u001B[32m     16\u001B[39m     meta_table,\n\u001B[32m     17\u001B[39m )\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_ops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m OpOverload\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_prims\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\torch\\_decomp\\__init__.py:276\u001B[39m\n\u001B[32m    272\u001B[39m             decompositions.pop(op, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    275\u001B[39m \u001B[38;5;66;03m# populate the table\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m276\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_decomp\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdecompositions\u001B[39;00m\n\u001B[32m    277\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_refs\u001B[39;00m\n\u001B[32m    280\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcore_aten_decompositions\u001B[39m() -> \u001B[33m\"\u001B[39m\u001B[33mCustomDecompTable\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\torch\\_decomp\\decompositions.py:16\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_meta_registrations\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_prims\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mprims\u001B[39;00m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_prims_common\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mutils\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfunctional\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mF\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\torch\\_prims\\__init__.py:37\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01moverrides\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m handle_torch_function, has_torch_function\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_pytree\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tree_flatten, tree_map, tree_unflatten\n\u001B[32m---> \u001B[39m\u001B[32m37\u001B[39m prim = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlibrary\u001B[49m\u001B[43m.\u001B[49m\u001B[43mLibrary\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprims\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mDEF\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     38\u001B[39m prim_impl = torch.library.Library(\u001B[33m\"\u001B[39m\u001B[33mprims\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mIMPL\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mCompositeExplicitAutograd\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     39\u001B[39m prim_backend_select_impl = torch.library.Library(\u001B[33m\"\u001B[39m\u001B[33mprims\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mIMPL\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mBackendSelect\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\torch\\library.py:109\u001B[39m, in \u001B[36mLibrary.__init__\u001B[39m\u001B[34m(self, ns, kind, dispatch_key)\u001B[39m\n\u001B[32m    107\u001B[39m frame = traceback.extract_stack(limit=\u001B[32m2\u001B[39m)[\u001B[32m0\u001B[39m]\n\u001B[32m    108\u001B[39m filename, lineno = frame.filename, frame.lineno\n\u001B[32m--> \u001B[39m\u001B[32m109\u001B[39m \u001B[38;5;28mself\u001B[39m.m: Optional[Any] = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_C\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_dispatch_library\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    110\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkind\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdispatch_key\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlineno\u001B[49m\n\u001B[32m    111\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    112\u001B[39m \u001B[38;5;28mself\u001B[39m.ns = ns\n\u001B[32m    113\u001B[39m \u001B[38;5;28mself\u001B[39m._op_defs: \u001B[38;5;28mset\u001B[39m[\u001B[38;5;28mstr\u001B[39m] = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[31mRuntimeError\u001B[39m: Only a single TORCH_LIBRARY can be used to register the namespace prims; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at C:\\Users\\KIIT0001\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\torch\\_prims\\__init__.py:37; latest registration was registered at C:\\Users\\KIIT0001\\Desktop\\AdvancedProgramming\\.venv\\Lib\\site-packages\\torch\\_prims\\__init__.py:37"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aa7451c3711384e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
